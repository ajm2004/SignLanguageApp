{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Landmarks - Pipeline_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting collection for: A\n",
      "Error during image processing: could not broadcast input array from shape (501,500,3) into shape (500,500,3)\n",
      "Error during image processing: could not broadcast input array from shape (501,500,3) into shape (500,500,3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import mediapipe as mp\n",
    "\n",
    "# ----------------------------\n",
    "# Initialize MediaPipe Selfie Segmentation\n",
    "# ----------------------------\n",
    "mp_selfie_segmentation = mp.solutions.selfie_segmentation\n",
    "segmentation = mp_selfie_segmentation.SelfieSegmentation(model_selection=1)\n",
    "\n",
    "# ----------------------------\n",
    "# Initialize Webcam and Hand Detector\n",
    "# ----------------------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector(maxHands=1)\n",
    "\n",
    "# Constants and folders for saving images\n",
    "imgSize = 500\n",
    "baseFolder = \"C:/Users/User/OneDrive/Documents/SignLanguageApp/SLangDataset/JustZ\"\n",
    "letters = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\", \"HI\", \"Space\"]  # List of letters A-Y \n",
    "maxImages = 600         # Total images to capture per class\n",
    "paddingFactor = 0.45     # Padding percentage\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# ----------------------------\n",
    "# Utility function: Process and resize image for saving\n",
    "# ----------------------------\n",
    "def process_and_resize(imgCrop, aspectRatio, imgSize):\n",
    "    channels = 1 if len(imgCrop.shape) == 2 else imgCrop.shape[2]\n",
    "    imgWhite = np.ones((imgSize, imgSize, channels), np.uint8) * 0\n",
    "    try:\n",
    "        if aspectRatio > 1:\n",
    "            # Height > width:\n",
    "            k = imgSize / imgCrop.shape[0]\n",
    "            wCal = math.ceil(k * imgCrop.shape[1])\n",
    "            imgResize = cv2.resize(imgCrop, (wCal, imgSize))\n",
    "            wGap = math.ceil((imgSize - wCal) / 2)\n",
    "            imgWhite[:, wGap:wCal + wGap] = imgResize\n",
    "        else:\n",
    "            # Width >= height:\n",
    "            k = imgSize / imgCrop.shape[1]\n",
    "            hCal = math.ceil(k * imgCrop.shape[0])\n",
    "            imgResize = cv2.resize(imgCrop, (imgSize, hCal))\n",
    "            hGap = math.ceil((imgSize - hCal) / 2)\n",
    "            imgWhite[hGap:hCal + hGap, :] = imgResize\n",
    "    except Exception as e:\n",
    "        print(f\"Error during image processing: {e}\")\n",
    "        return None\n",
    "    return imgWhite\n",
    "\n",
    "# ----------------------------\n",
    "# ----------------------------\n",
    "def detect_skin(frame):\n",
    "    ycrcb = cv2.cvtColor(frame, cv2.COLOR_BGR2YCrCb)\n",
    "    lower_skin = np.array([0, 133, 77], dtype=np.uint8)\n",
    "    upper_skin = np.array([255, 173, 127], dtype=np.uint8)\n",
    "    mask = cv2.inRange(ycrcb, lower_skin, upper_skin)\n",
    "    \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.GaussianBlur(mask, (5, 5), 0)\n",
    "    \n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_mask = np.zeros_like(mask)\n",
    "    cv2.drawContours(contour_mask, contours, -1, 255, thickness=cv2.FILLED)\n",
    "    mask = cv2.bitwise_and(mask, contour_mask)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "# ----------------------------\n",
    "# Main Loop: Process each class (letter)\n",
    "# ----------------------------\n",
    "for className in letters:\n",
    "    print(f\"Starting collection for: {className}\")\n",
    "    folder = os.path.join(baseFolder, className)\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    counter, collecting = 0, False\n",
    "\n",
    "    while counter < maxImages:\n",
    "        success, img = cap.read()\n",
    "        if not success:\n",
    "            print(\"Camera access failed.\")\n",
    "            break\n",
    "\n",
    "        # Detect hand in the full image\n",
    "        hands, _ = detector.findHands(img, draw=False)\n",
    "        if hands:\n",
    "            # Use the first detected hand\n",
    "            hand = hands[0]\n",
    "            bbox = hand['bbox']       # [x, y, w, h]\n",
    "            lm_list = hand['lmList']    # List of landmarks in full-image coordinates\n",
    "            x, y, w, h = bbox\n",
    "\n",
    "            # Calculate padding based on hand size\n",
    "            xPad = int(w * paddingFactor)\n",
    "            yPad = int(h * paddingFactor)\n",
    "\n",
    "            # Compute crop boundaries (ensure they stay within image bounds)\n",
    "            crop_x1 = max(0, x - xPad)\n",
    "            crop_y1 = max(0, y - yPad)\n",
    "            crop_x2 = min(x + w + xPad, img.shape[1])\n",
    "            crop_y2 = min(y + h + yPad, img.shape[0])\n",
    "            imgCrop = img[crop_y1:crop_y2, crop_x1:crop_x2]\n",
    "\n",
    "            if imgCrop.size > 0:\n",
    "                # -----------------------------------------------------\n",
    "                # STEP A: Apply segmentation to remove background\n",
    "                # -----------------------------------------------------\n",
    "                rgb_crop = cv2.cvtColor(imgCrop, cv2.COLOR_BGR2RGB)\n",
    "                results_seg = segmentation.process(rgb_crop)\n",
    "                mask_seg = results_seg.segmentation_mask\n",
    "                seg_threshold = 0.5  # Adjust threshold if necessary\n",
    "                mask_binary_seg = (mask_seg > seg_threshold).astype(np.uint8) * 255\n",
    "                mask_binary_seg = cv2.cvtColor(mask_binary_seg, cv2.COLOR_GRAY2BGR)\n",
    "                segmented_crop = cv2.bitwise_and(imgCrop, mask_binary_seg)\n",
    "                \n",
    "                # Show the segmented crop (background removed)\n",
    "                cv2.imshow(\"Segmented Crop\", segmented_crop)\n",
    "                \n",
    "                # -----------------------------------------------------\n",
    "                # STEP 1: Draw landmarks on the segmented crop\n",
    "                # -----------------------------------------------------\n",
    "                imgCrop_landmarked = segmented_crop.copy()\n",
    "                for lm in lm_list:\n",
    "                    adj_x = lm[0] - crop_x1\n",
    "                    adj_y = lm[1] - crop_y1\n",
    "                    cv2.circle(imgCrop_landmarked, (adj_x, adj_y), 4, (0, 0, 255), -1)\n",
    "                for connection in mp.solutions.hands.HAND_CONNECTIONS:\n",
    "                    pt1 = lm_list[connection[0]]\n",
    "                    pt2 = lm_list[connection[1]]\n",
    "                    pt1_adjusted = (pt1[0] - crop_x1, pt1[1] - crop_y1)\n",
    "                    pt2_adjusted = (pt2[0] - crop_x1, pt2[1] - crop_y1)\n",
    "                    cv2.line(imgCrop_landmarked, pt1_adjusted, pt2_adjusted, (0, 0, 255), 2)\n",
    "                \n",
    "                # -----------------------------------------------------\n",
    "                # STEP 2: Convert the segmented crop directly to a binary image\n",
    "                # -----------------------------------------------------\n",
    "                # Create a blank image for the binary result\n",
    "                binary_result = np.zeros_like(segmented_crop)\n",
    "                # Convert the segmented crop to grayscale and threshold it\n",
    "                gray = cv2.cvtColor(segmented_crop, cv2.COLOR_BGR2GRAY)\n",
    "                _, binary_from_seg = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "                binary_result[binary_from_seg > 0] = [255, 255, 255]\n",
    "                # Overlay landmarks (drawn in black) on the binary image\n",
    "                for lm in lm_list:\n",
    "                    adj_x = lm[0] - crop_x1\n",
    "                    adj_y = lm[1] - crop_y1\n",
    "                    cv2.circle(binary_result, (adj_x, adj_y), 4, (0, 0, 0), -1)\n",
    "                for connection in mp.solutions.hands.HAND_CONNECTIONS:\n",
    "                    pt1 = lm_list[connection[0]]\n",
    "                    pt2 = lm_list[connection[1]]\n",
    "                    pt1_adjusted = (pt1[0] - crop_x1, pt1[1] - crop_y1)\n",
    "                    pt2_adjusted = (pt2[0] - crop_x1, pt2[1] - crop_y1)\n",
    "                    cv2.line(binary_result, pt1_adjusted, pt2_adjusted, (0, 0, 0), 2)\n",
    "                \n",
    "                # -----------------------------------------------------\n",
    "                # STEP 3: Resize the binary image for saving/visualization\n",
    "                # -----------------------------------------------------\n",
    "                aspectRatio = (crop_y2 - crop_y1) / (crop_x2 - crop_x1)\n",
    "                imgWhite = process_and_resize(binary_result, aspectRatio, imgSize)\n",
    "                if imgWhite is not None:\n",
    "                    cv2.imshow(\"Processed Binary Image\", imgWhite)\n",
    "                    if collecting:\n",
    "                        counter += 1\n",
    "                        savePath = os.path.join(folder, f\"{className.lower()}_{counter}.jpg\")\n",
    "                        cv2.imwrite(savePath, imgWhite)\n",
    "                        print(f\"Saved {counter}/{maxImages} images for {className}\")\n",
    "\n",
    "        # Show the original live feed (for reference)\n",
    "        cv2.imshow(\"Live Feed with Landmarks\", img)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('s'):\n",
    "            collecting = True\n",
    "        if key == ord('p'):\n",
    "            collecting = False\n",
    "\n",
    "    print(f\"Completed collection for {className}\")\n",
    "    input(\"Press Enter for next class.\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just Binary - Pieline_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting collection for: A\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import mediapipe as mp\n",
    "\n",
    "# ----------------------------\n",
    "# Initialize MediaPipe Selfie Segmentation\n",
    "# ----------------------------\n",
    "mp_selfie_segmentation = mp.solutions.selfie_segmentation\n",
    "segmentation = mp_selfie_segmentation.SelfieSegmentation(model_selection=1)\n",
    "\n",
    "# ----------------------------\n",
    "# Initialize Webcam and Hand Detector\n",
    "# ----------------------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector(maxHands=1)\n",
    "\n",
    "# Constants and folders for saving images\n",
    "imgSize = 500\n",
    "baseFolder = \"C:/Users/User/OneDrive/Documents/SignLanguageApp/SLangDataset/JustZ\"\n",
    "letters = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\", \"HI\", \"Space\"]  # List of classes\n",
    "maxImages = 600         # Total images to capture per class\n",
    "paddingFactor = 0.45     # Padding percentage\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# ----------------------------\n",
    "# Utility function: Process and resize image for saving\n",
    "# ----------------------------\n",
    "def process_and_resize(imgCrop, aspectRatio, imgSize):\n",
    "    channels = 1 if len(imgCrop.shape) == 2 else imgCrop.shape[2]\n",
    "    imgWhite = np.ones((imgSize, imgSize, channels), np.uint8) * 0\n",
    "    try:\n",
    "        if aspectRatio > 1:\n",
    "            # Height > width:\n",
    "            k = imgSize / imgCrop.shape[0]\n",
    "            wCal = math.ceil(k * imgCrop.shape[1])\n",
    "            imgResize = cv2.resize(imgCrop, (wCal, imgSize))\n",
    "            wGap = math.ceil((imgSize - wCal) / 2)\n",
    "            imgWhite[:, wGap:wCal + wGap] = imgResize\n",
    "        else:\n",
    "            # Width >= height:\n",
    "            k = imgSize / imgCrop.shape[1]\n",
    "            hCal = math.ceil(k * imgCrop.shape[0])\n",
    "            imgResize = cv2.resize(imgCrop, (imgSize, hCal))\n",
    "            hGap = math.ceil((imgSize - hCal) / 2)\n",
    "            imgWhite[hGap:hCal + hGap, :] = imgResize\n",
    "    except Exception as e:\n",
    "        print(f\"Error during image processing: {e}\")\n",
    "        return None\n",
    "    return imgWhite\n",
    "\n",
    "# ----------------------------\n",
    "# (Optional) Utility function: Detect skin using YCrCb thresholds\n",
    "# (Not used in the updated processing)\n",
    "# ----------------------------\n",
    "def detect_skin(frame):\n",
    "    ycrcb = cv2.cvtColor(frame, cv2.COLOR_BGR2YCrCb)\n",
    "    lower_skin = np.array([0, 133, 77], dtype=np.uint8)\n",
    "    upper_skin = np.array([255, 173, 127], dtype=np.uint8)\n",
    "    mask = cv2.inRange(ycrcb, lower_skin, upper_skin)\n",
    "    \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.GaussianBlur(mask, (5, 5), 0)\n",
    "    \n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_mask = np.zeros_like(mask)\n",
    "    cv2.drawContours(contour_mask, contours, -1, 255, thickness=cv2.FILLED)\n",
    "    mask = cv2.bitwise_and(mask, contour_mask)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "# ----------------------------\n",
    "# Main Loop: Process each class\n",
    "# ----------------------------\n",
    "for className in letters:\n",
    "    print(f\"Starting collection for: {className}\")\n",
    "    folder = os.path.join(baseFolder, className)\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    counter, collecting = 0, False\n",
    "\n",
    "    while counter < maxImages:\n",
    "        success, img = cap.read()\n",
    "        if not success:\n",
    "            print(\"Camera access failed.\")\n",
    "            break\n",
    "\n",
    "        # Detect hand in the full image\n",
    "        hands, _ = detector.findHands(img, draw=False)\n",
    "        if hands:\n",
    "            # Use the first detected hand\n",
    "            hand = hands[0]\n",
    "            bbox = hand['bbox']       # [x, y, w, h]\n",
    "            x, y, w, h = bbox\n",
    "\n",
    "            # Calculate padding based on hand size\n",
    "            xPad = int(w * paddingFactor)\n",
    "            yPad = int(h * paddingFactor)\n",
    "\n",
    "            # Compute crop boundaries (ensure they stay within image bounds)\n",
    "            crop_x1 = max(0, x - xPad)\n",
    "            crop_y1 = max(0, y - yPad)\n",
    "            crop_x2 = min(x + w + xPad, img.shape[1])\n",
    "            crop_y2 = min(y + h + yPad, img.shape[0])\n",
    "            imgCrop = img[crop_y1:crop_y2, crop_x1:crop_x2]\n",
    "\n",
    "            if imgCrop.size > 0:\n",
    "                # -----------------------------------------------------\n",
    "                # STEP A: Apply segmentation to remove background\n",
    "                # -----------------------------------------------------\n",
    "                rgb_crop = cv2.cvtColor(imgCrop, cv2.COLOR_BGR2RGB)\n",
    "                results_seg = segmentation.process(rgb_crop)\n",
    "                mask_seg = results_seg.segmentation_mask\n",
    "                seg_threshold = 0.5  # Adjust threshold if necessary\n",
    "                mask_binary_seg = (mask_seg > seg_threshold).astype(np.uint8) * 255\n",
    "                mask_binary_seg = cv2.cvtColor(mask_binary_seg, cv2.COLOR_GRAY2BGR)\n",
    "                segmented_crop = cv2.bitwise_and(imgCrop, mask_binary_seg)\n",
    "                \n",
    "                # Show the segmented crop (background removed)\n",
    "                cv2.imshow(\"Segmented Crop\", segmented_crop)\n",
    "                \n",
    "                # -----------------------------------------------------\n",
    "                # STEP 2: Convert the segmented crop directly to a binary image\n",
    "                # (Without overlaying landmarks)\n",
    "                # -----------------------------------------------------\n",
    "                gray = cv2.cvtColor(segmented_crop, cv2.COLOR_BGR2GRAY)\n",
    "                _, binary_from_seg = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "                # Create a binary result image: white where segmented, black elsewhere\n",
    "                binary_result = np.zeros_like(segmented_crop)\n",
    "                binary_result[binary_from_seg > 0] = [255, 255, 255]\n",
    "                \n",
    "                # -----------------------------------------------------\n",
    "                # STEP 3: Resize the binary image for saving/visualization\n",
    "                # -----------------------------------------------------\n",
    "                aspectRatio = (crop_y2 - crop_y1) / (crop_x2 - crop_x1)\n",
    "                imgWhite = process_and_resize(binary_result, aspectRatio, imgSize)\n",
    "                if imgWhite is not None:\n",
    "                    cv2.imshow(\"Processed Binary Image\", imgWhite)\n",
    "                    if collecting:\n",
    "                        counter += 1\n",
    "                        savePath = os.path.join(folder, f\"{className.lower()}_{counter}.jpg\")\n",
    "                        cv2.imwrite(savePath, imgWhite)\n",
    "                        print(f\"Saved {counter}/{maxImages} images for {className}\")\n",
    "\n",
    "        # Show the original live feed (for reference)\n",
    "        cv2.imshow(\"Live Feed\", img)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('s'):\n",
    "            collecting = True\n",
    "        if key == ord('p'):\n",
    "            collecting = False\n",
    "\n",
    "    print(f\"Completed collection for {className}\")\n",
    "    input(\"Press Enter for next class.\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
